{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "MNIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "trans = [transforms.ToTensor()]\n",
    "trans.insert(0, transforms.Resize(224))\n",
    "trans = transforms.Compose(trans)\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, transform=trans)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, transform=trans)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "def make_iters(train_data, test_data, batch_size, num_workers=8):\n",
    "    return (data.DataLoader(train_data, batch_size, shuffle=True,\n",
    "                            num_workers=num_workers),\n",
    "            data.DataLoader(test_data, batch_size, shuffle=False,\n",
    "                            num_workers=num_workers))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dev = 'mps'\n",
    "# dev = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true,y_pred_cls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "VGG16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class res_Block(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=in_channels // 4, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(in_channels//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=in_channels // 4, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.block(x)\n",
    "        if out.shape == x.shape:\n",
    "            return out+x\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            # nn.MaxPool2d(2),\n",
    "            res_Block(64, 64),\n",
    "            nn.MaxPool2d(2),\n",
    "            # res_Block(128, 64),\n",
    "            nn.Conv2d(64, 16, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200704, 4096), nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024), nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "\n",
    "net = LeNet().to(dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0;31m<<<<<< üêå cpu is used >>>>>>\u001B[0m\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "Conv2d-1                          [-1, 64, 224, 224]                  640\n",
      "ReLU-2                            [-1, 64, 224, 224]                    0\n",
      "Conv2d-3                          [-1, 16, 224, 224]                1,040\n",
      "BatchNorm2d-4                     [-1, 16, 224, 224]                   32\n",
      "ReLU-5                            [-1, 16, 224, 224]                    0\n",
      "Conv2d-6                          [-1, 64, 224, 224]                9,280\n",
      "BatchNorm2d-7                     [-1, 64, 224, 224]                  128\n",
      "ReLU-8                            [-1, 64, 224, 224]                    0\n",
      "MaxPool2d-9                       [-1, 64, 112, 112]                    0\n",
      "Conv2d-10                         [-1, 16, 112, 112]                9,232\n",
      "ReLU-11                           [-1, 16, 112, 112]                    0\n",
      "Flatten-12                              [-1, 200704]                    0\n",
      "Linear-13                                 [-1, 4096]          822,087,680\n",
      "ReLU-14                                   [-1, 4096]                    0\n",
      "Dropout-15                                [-1, 4096]                    0\n",
      "Linear-16                                 [-1, 1024]            4,195,328\n",
      "ReLU-17                                   [-1, 1024]                    0\n",
      "Dropout-18                                [-1, 1024]                    0\n",
      "Linear-19                                   [-1, 10]               10,250\n",
      "==========================================================================\n",
      "Total params: 826,313,610\n",
      "Trainable params: 826,313,610\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000069\n",
      "Forward/backward pass size (MB): 151.711014\n",
      "Params size (MB): 3152.136269\n",
      "Estimated Total Size (MB): 3303.847351\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchkeras as torchkeras\n",
    "from torchkeras.metrics import Accuracy\n",
    "from torchkeras import summary\n",
    "\n",
    "model = torchkeras.KerasModel(net,\n",
    "                              loss_fn = nn.CrossEntropyLoss(),\n",
    "                              optimizer= torch.optim.SGD(net.parameters(),lr = 0.0001),\n",
    "                              metrics_dict = {\"acc\":Accuracy()}\n",
    "                             )    # Â∞ÅË£ÖÊàê‰∫ÜkerasÈáåÈù¢Ê®°ÂûãÁöÑÊ†ºÂºè\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "train_iter, test_iter = make_iters(mnist_train, mnist_test, batch_size)\n",
    "\n",
    "for features,labels in train_iter:\n",
    "    break\n",
    "\n",
    "summary(model, input_data=features);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0625"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred.to('cpu')),dim=1).data\n",
    "    return accuracy_score(y_true.to('cpu'),y_pred_cls)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters(),lr = 0.01)\n",
    "metric_func = accuracy\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "net = net.to(dev)\n",
    "\n",
    "metric_func(net(features.to(dev)), labels.to(dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "================================================================================2022-11-18 09:01:21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m predictions \u001B[38;5;241m=\u001B[39m net(features)\n\u001B[1;32m     26\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_func(predictions,labels)\n\u001B[0;32m---> 27\u001B[0m metric \u001B[38;5;241m=\u001B[39m \u001B[43mmetric_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# ÂèçÂêë‰º†Êí≠Ê±ÇÊ¢ØÂ∫¶\u001B[39;00m\n\u001B[1;32m     30\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36maccuracy\u001B[0;34m(y_pred, y_true)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maccuracy\u001B[39m(y_pred,y_true):\n\u001B[0;32m----> 7\u001B[0m     y_pred_cls \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(nn\u001B[38;5;241m.\u001B[39mSoftmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)(\u001B[43my_pred\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_score(y_true\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m),y_pred_cls)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "log_step_freq = 10\n",
    "\n",
    "dfhistory = pd.DataFrame(columns = [\"epoch\",\"loss\",metric_name,\"val_loss\",\"val_\"+metric_name])\n",
    "print(\"Start Training...\")\n",
    "nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "\n",
    "    # 1ÔºåËÆ≠ÁªÉÂæ™ÁéØ-------------------------------------------------\n",
    "    net.train()\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "\n",
    "    for step, (features,labels) in enumerate(train_iter, 1):\n",
    "\n",
    "        features = features.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "\n",
    "        # Ê¢ØÂ∫¶Ê∏ÖÈõ∂\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ê≠£Âêë‰º†Êí≠Ê±ÇÊçüÂ§±\n",
    "        predictions = net(features)\n",
    "        loss = loss_func(predictions,labels)\n",
    "        metric = metric_func(predictions,labels)\n",
    "\n",
    "        # ÂèçÂêë‰º†Êí≠Ê±ÇÊ¢ØÂ∫¶\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ÊâìÂç∞batchÁ∫ßÂà´Êó•Âøó\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step%log_step_freq == 0:\n",
    "            print((\"[step = %d] loss: %.3f, \"+metric_name+\": %.3f\") %\n",
    "                  (step, loss_sum/step, metric_sum/step))\n",
    "\n",
    "    # 2ÔºåÈ™åËØÅÂæ™ÁéØ-------------------------------------------------\n",
    "    net.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "\n",
    "    for val_step, (features,labels) in enumerate(test_iter, 1):\n",
    "        features = features.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "        with torch.no_grad():\n",
    "            predictions = net(features)\n",
    "            val_loss = loss_func(predictions,labels)\n",
    "            val_metric = metric_func(predictions,labels)\n",
    "\n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "\n",
    "    # 3ÔºåËÆ∞ÂΩïÊó•Âøó-------------------------------------------------\n",
    "    info = (epoch, loss_sum/step, metric_sum/step,\n",
    "            val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "\n",
    "    # ÊâìÂç∞epochÁ∫ßÂà´Êó•Âøó\n",
    "    print((\"\\nEPOCH = %d, loss = %.3f,\"+ metric_name + \\\n",
    "          \"  = %.3f, val_loss = %.3f, \"+\"val_\"+ metric_name+\" = %.3f\")\n",
    "          %info)\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "print('Finished Training...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ËßÇÂØüÊçüÂ§±ÂíåÂáÜÁ°ÆÁéáÁöÑÂèòÂåñ\n",
    "plot_metric(dfhistory,\"loss\")\n",
    "plot_metric(dfhistory,\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GoogleNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans = [transforms.ToTensor()]\n",
    "trans.insert(0, transforms.Resize(96))\n",
    "trans = transforms.Compose(trans)\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, transform=trans)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, transform=trans)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4ÊòØÊØèÊù°Ë∑ØÂæÑÁöÑËæìÂá∫ÈÄöÈÅìÊï∞\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # Á∫øË∑Ø1ÔºåÂçï1x1Âç∑ÁßØÂ±Ç\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # Á∫øË∑Ø2Ôºå1x1Âç∑ÁßØÂ±ÇÂêéÊé•3x3Âç∑ÁßØÂ±Ç\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # Á∫øË∑Ø3Ôºå1x1Âç∑ÁßØÂ±ÇÂêéÊé•5x5Âç∑ÁßØÂ±Ç\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # Á∫øË∑Ø4Ôºå3x3ÊúÄÂ§ßÊ±áËÅöÂ±ÇÂêéÊé•1x1Âç∑ÁßØÂ±Ç\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # Âú®ÈÄöÈÅìÁª¥Â∫¶‰∏äËøûÁªìËæìÂá∫\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "# stage2 1*1 Âç∑ÁßØ 3*3 Âç∑ÁßØ  3*3 ÊúÄÂ§ßÊ±†Âåñ\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "# stage3 ‰∏§‰∏™InceptionÂùóÔºå 3*3 ÊúÄÂ§ßÊ±†Âåñ  Ëøõ‰∏ÄÊ≠•ÈôçÁª¥\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "# stage4 5‰∏™InceptionÂùóÔºå 3*3 ÊúÄÂ§ßÊ±†Âåñ  Ëøõ‰∏ÄÊ≠•ÈôçÁª¥\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   # Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   # Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   # Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "# stage5 2‰∏™InceptionÂùóÔºå 1*1 Âπ≥ÂùáÊ±†Âåñ\n",
    "b5 = nn.Sequential(Inception(512, 128, (160, 320), (32, 128), 128),\n",
    "                   # Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(704, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchkeras as torchkeras\n",
    "from torchkeras.metrics import Accuracy\n",
    "from torchkeras import summary\n",
    "\n",
    "model = torchkeras.KerasModel(net,\n",
    "                              loss_fn = nn.CrossEntropyLoss(),\n",
    "                              optimizer= torch.optim.SGD(net.parameters(),lr = 0.0001),\n",
    "                              metrics_dict = {\"acc\":Accuracy()}\n",
    "                             )    # Â∞ÅË£ÖÊàê‰∫ÜkerasÈáåÈù¢Ê®°ÂûãÁöÑÊ†ºÂºè\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "train_iter, test_iter = make_iters(mnist_train, mnist_test, batch_size)\n",
    "\n",
    "for features,labels in train_iter:\n",
    "    break\n",
    "\n",
    "summary(model, input_data=features);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred.to('cpu')),dim=1).data\n",
    "    return accuracy_score(y_true.to('cpu'),y_pred_cls)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters(),lr = 0.1)\n",
    "metric_func = accuracy\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "net = net.to(dev)\n",
    "\n",
    "metric_func(net(features.to(dev)), labels.to(dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_step_freq = 100\n",
    "\n",
    "dfhistory = pd.DataFrame(columns = [\"epoch\",\"loss\",metric_name,\"val_loss\",\"val_\"+metric_name])\n",
    "print(\"Start Training...\")\n",
    "nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "\n",
    "    # 1ÔºåËÆ≠ÁªÉÂæ™ÁéØ-------------------------------------------------\n",
    "    net.train()\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "\n",
    "    for step, (features,labels) in enumerate(train_iter, 1):\n",
    "\n",
    "        features = features.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "\n",
    "        # Ê¢ØÂ∫¶Ê∏ÖÈõ∂\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ê≠£Âêë‰º†Êí≠Ê±ÇÊçüÂ§±\n",
    "        predictions = net(features)\n",
    "        loss = loss_func(predictions,labels)\n",
    "        metric = metric_func(predictions,labels)\n",
    "\n",
    "        # ÂèçÂêë‰º†Êí≠Ê±ÇÊ¢ØÂ∫¶\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ÊâìÂç∞batchÁ∫ßÂà´Êó•Âøó\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step%log_step_freq == 0:\n",
    "            print((\"[step = %d] loss: %.3f, \"+metric_name+\": %.3f\") %\n",
    "                  (step, loss_sum/step, metric_sum/step))\n",
    "\n",
    "    # 2ÔºåÈ™åËØÅÂæ™ÁéØ-------------------------------------------------\n",
    "    net.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "\n",
    "    for val_step, (features,labels) in enumerate(test_iter, 1):\n",
    "        features = features.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "        with torch.no_grad():\n",
    "            predictions = net(features)\n",
    "            val_loss = loss_func(predictions,labels)\n",
    "            val_metric = metric_func(predictions,labels)\n",
    "\n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "\n",
    "    # 3ÔºåËÆ∞ÂΩïÊó•Âøó-------------------------------------------------\n",
    "    info = (epoch, loss_sum/step, metric_sum/step,\n",
    "            val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "\n",
    "    # ÊâìÂç∞epochÁ∫ßÂà´Êó•Âøó\n",
    "    print((\"\\nEPOCH = %d, loss = %.3f,\"+ metric_name + \\\n",
    "          \"  = %.3f, val_loss = %.3f, \"+\"val_\"+ metric_name+\" = %.3f\")\n",
    "          %info)\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "print('Finished Training...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
